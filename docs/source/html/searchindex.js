Search.setIndex({docnames:["api","auralflow","auralflow.datasets","auralflow.losses","auralflow.models","auralflow.trainer","auralflow.utils","auralflow.visualizer","index","modules"],envversion:{"sphinx.domains.c":2,"sphinx.domains.changeset":1,"sphinx.domains.citation":1,"sphinx.domains.cpp":5,"sphinx.domains.index":1,"sphinx.domains.javascript":2,"sphinx.domains.math":2,"sphinx.domains.python":3,"sphinx.domains.rst":2,"sphinx.domains.std":2,sphinx:56},filenames:["api.rst","auralflow.rst","auralflow.datasets.rst","auralflow.losses.rst","auralflow.models.rst","auralflow.trainer.rst","auralflow.utils.rst","auralflow.visualizer.rst","index.rst","modules.rst"],objects:{"":[[1,0,0,"-","auralflow"]],"auralflow.datasets":[[2,1,1,"","AudioDataset"],[2,1,1,"","AudioFolder"],[2,3,1,"","audio_to_disk"],[2,3,1,"","create_audio_dataset"],[2,3,1,"","create_audio_folder"],[2,3,1,"","load_dataset"]],"auralflow.datasets.AudioFolder":[[2,2,1,"","split"]],"auralflow.losses":[[3,1,1,"","KLDivergenceLoss"],[3,1,1,"","L1Loss"],[3,1,1,"","L2Loss"],[3,1,1,"","L2MaskLoss"],[3,1,1,"","RMSELoss"],[3,1,1,"","SIDRLoss"],[3,1,1,"","WeightedComponentLoss"],[3,3,1,"","component_loss"],[3,3,1,"","get_evaluation_metrics"],[3,3,1,"","get_model_criterion"],[3,3,1,"","kl_div_loss"],[3,3,1,"","si_sdr_loss"]],"auralflow.losses.KLDivergenceLoss":[[3,2,1,"","forward"],[3,4,1,"","training"]],"auralflow.losses.L1Loss":[[3,2,1,"","forward"],[3,4,1,"","training"]],"auralflow.losses.L2Loss":[[3,2,1,"","forward"],[3,4,1,"","training"]],"auralflow.losses.L2MaskLoss":[[3,2,1,"","forward"],[3,4,1,"","training"]],"auralflow.losses.RMSELoss":[[3,2,1,"","forward"],[3,4,1,"","training"]],"auralflow.losses.SIDRLoss":[[3,2,1,"","forward"],[3,4,1,"","training"]],"auralflow.losses.WeightedComponentLoss":[[3,2,1,"","forward"],[3,4,1,"","training"]],"auralflow.separate":[[1,3,1,"","separate_audio"]],"auralflow.test":[[1,3,1,"","main"]],"auralflow.train":[[1,3,1,"","main"]],"auralflow.trainer":[[5,3,1,"","run_training"],[5,3,1,"","run_validation"]],"auralflow.utils":[[6,3,1,"","load_config"],[6,3,1,"","load_object"],[6,3,1,"","pull_config_template"],[6,3,1,"","save_config"],[6,3,1,"","save_object"]],"auralflow.visualizer":[[7,1,1,"","ProgressBar"],[7,1,1,"","Visualizer"],[7,3,1,"","config_visualizer"]],"auralflow.visualizer.Visualizer":[[7,4,1,"","audio"],[7,2,1,"","embed_audio"],[7,2,1,"","save_figure"],[7,4,1,"","spectrogram"],[7,2,1,"","test_model"],[7,2,1,"","visualize"],[7,2,1,"","visualize_gradient"],[7,2,1,"","visualize_spectrogram"],[7,2,1,"","visualize_waveform"]],auralflow:[[2,0,0,"-","datasets"],[3,0,0,"-","losses"],[4,0,0,"-","models"],[1,0,0,"-","separate"],[1,0,0,"-","test"],[1,0,0,"-","train"],[5,0,0,"-","trainer"],[6,0,0,"-","utils"],[7,0,0,"-","visualizer"]]},objnames:{"0":["py","module","Python module"],"1":["py","class","Python class"],"2":["py","method","Python method"],"3":["py","function","Python function"],"4":["py","attribute","Python attribute"]},objtypes:{"0":"py:module","1":"py:class","2":"py:method","3":"py:function","4":"py:attribute"},terms:{"0":[2,3],"1":[2,3,7],"10":7,"10000":2,"1000000":2,"16000":3,"2":[2,3],"20":1,"200":1,"3":[2,3,7],"30":1,"44100":[1,2,7],"8":3,"9":7,"class":[2,3,7],"default":2,"float":[2,3],"function":3,"int":[1,2,3,6,7],"new":6,"return":[1,2,3,7],"true":[2,3,7],"while":3,If:2,The:[2,3],_:7,__:7,accord:3,afterward:3,against:3,all:3,alloc:2,alpha:3,although:3,amount:3,an:[2,7],api:8,ar:2,argument:3,attach:6,attenu:3,audio:[1,2,7],audio_format:2,audio_to_disk:2,audiodataset:2,audiofold:2,backend:2,balanc:3,bar:7,base:[1,2,3,5,7],batch:3,beta:3,bool:[2,3,7],bootstrap:2,both:2,calcul:3,call:3,callabl:3,callback:5,can:2,care:3,channel:2,checkpoint:6,chunk:2,chunk_siz:2,clip:2,close:3,collect:2,combin:3,compon:3,component_loss:3,comput:3,config:[3,6,7],config_filepath:[1,6],config_visu:7,configur:[1,3,6],consider:2,consist:2,construct:3,copi:6,creat:2,create_audio_dataset:2,create_audio_fold:2,criterion:3,csv:1,d_kl:3,data:[2,5,6],dataload:[2,5],dataset:1,dataset_param:2,dataset_path:2,defin:3,depend:3,design:2,dict:[2,3,6,7],directli:[2,3],directori:[2,6],disk:2,distribut:3,diverg:3,down:2,due:2,durat:[1,2],dure:7,e:2,each:2,effect:2,effici:2,embed_audio:7,entir:2,especi:2,estim:3,eval:3,eventu:2,everi:3,exampl:2,express:3,fals:7,few:2,figur:7,file:[1,2,3,6],filenam:[1,7],filepath:6,floattensor:3,fly:2,folder:2,form:3,format:2,former:3,forward:3,framework:7,from:[2,6,7],full:2,g:2,gener:2,get:3,get_evaluation_metr:3,get_model_criterion:3,given:[1,2,6],global_step:[6,7],gpu:2,gradient:7,ha:2,hook:3,howev:2,ignor:3,imag:7,imagefold:2,increas:2,index:8,infer:7,initi:7,instanc:3,instead:[2,3],iterabledataset:2,json:6,just:2,kl:3,kl_div_loss:3,kldivergenceloss:3,l1:3,l1loss:3,l2:3,l2loss:3,l2maskloss:3,label:7,larger:2,latter:3,lib:7,librari:7,list:2,listen:7,load:[2,6],load_config:6,load_dataset:2,load_object:6,locat:6,log:7,loop:5,loss:1,loss_fn:3,mai:2,main:1,make:2,manag:8,map:[1,3],mask:3,matplotlib:7,max_num_track:2,max_track:1,mean:3,memori:2,metric:1,mixtur:[3,7],mixture_audio:7,mode:7,model:[1,3,5,6,7],model_wrapp:6,mono:2,mu:3,much:2,multipl:2,n:3,need:[2,3],nn:3,nois:3,none:[1,2,3,5,6,7],normal:3,note:2,num_batch:3,num_channel:2,num_chunk:2,num_imag:7,number:2,obj_nam:6,object:[6,7],one:3,onli:3,option:[2,3],ordereddict:2,other:3,overlap:2,overridden:3,p:3,packag:8,pad:1,page:8,paramet:2,pass:3,path:[2,7],pathlib:7,perform:3,pin:2,pip:8,play_audio:7,process:2,progress:7,progressbar:7,pth:6,pull_config_templ:6,py:7,pypi:8,python3:7,python:7,pytorch:2,q:3,qualiti:3,randomli:2,rate:2,ratio:2,recip:3,reconstruct:3,reduc:2,regist:3,regular:3,replac:2,resampl:2,resample_r:1,residu:3,result:[2,7],rmse:3,rmseloss:3,root:2,run:[1,3,5,7],run_train:5,run_valid:5,runtim:2,s:[2,6],same:2,sampl:2,sample_length:2,sample_r:[2,7],save:[1,6,7],save_audio:7,save_config:6,save_dir:[6,7],save_figur:7,save_filepath:[1,6],save_freq:7,save_imag:7,save_object:6,score:3,script:1,sdr:3,search:8,send:7,separ:3,separate_audio:1,separationmodel:[1,5],set:2,should:3,si:3,si_sdr:3,si_sdr_loss:3,sidrloss:3,sigma:3,silent:3,similar:2,sinc:3,singl:1,site:7,slow:2,soundfil:2,sourc:[2,3],specif:2,spectrogram:7,sped:2,split:2,sr:[1,3],standard:3,state:6,std:7,stem:1,store:7,str:[1,2,3,6,7],streamabl:2,structur:2,subclass:3,subset:2,summarywrit:7,take:3,target:[2,3,7],target_audio:7,templat:6,tend:2,tensor:[1,3,7],tensorboard:7,term:3,test:2,test_model:7,them:3,thi:3,third:3,torch:[1,2,3,5,7],torchaudio:2,tqdm:7,track:[1,2],train:[2,3,5,7],train_dataload:5,trainer:1,training_param:2,trainingcallback:5,transfer:2,two:3,type:2,uncompress:2,under:6,union:[3,7],up:2,us:3,usag:2,util:[1,2,5,7],vae:3,val_dataload:5,val_split:2,valid:[2,5],varianc:2,version:7,versu:3,via:[2,8],viabl:2,view_gradi:7,view_spectrogram:7,view_waveform:7,visual:1,visualize_gradi:7,visualize_spectrogram:7,visualize_waveform:7,vocal:2,wav:2,waveform:7,weight:[3,7],weightedcomponentloss:3,when:2,where:3,which:2,wise:3,within:3,worker:2,worth:2,wrap:7,wrapper:[3,7],writer:7},titles:["API","auralflow package","auralflow.datasets package","auralflow.losses package","auralflow.models package","auralflow.trainer package","auralflow.utils package","auralflow.visualizer package","Auralflow Documentation","auralflow"],titleterms:{api:0,auralflow:[1,2,3,4,5,6,7,8,9],content:[1,2,3,4,5,6,7,8],dataset:2,document:8,indic:8,instal:8,loss:3,model:4,modul:[1,2,3,4,5,6,7],packag:[1,2,3,4,5,6,7],separ:1,submodul:[1,2,3,4,5,6,7],subpackag:1,tabl:8,test:1,train:1,trainer:5,util:6,visual:7}})