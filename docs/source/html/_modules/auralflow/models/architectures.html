<!doctype html>
<html class="no-js" lang="Python">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><link rel="index" title="Index" href="../../../genindex.html" /><link rel="search" title="Search" href="../../../search.html" />

    <meta name="generator" content="sphinx-4.5.0, furo 2022.06.04.1"/>
        <title>auralflow.models.architectures - auralflow</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo.css?digest=40978830699223671f4072448e654b5958f38b89" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    <link rel="stylesheet" type="text/css" href="../../../_static/../_static/css/custom.css" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  --color-foreground-primary: #212529;
  --color-brand-primary: #212529;
  --color-brand-content: #212529;
  --color-background-secondary: #f3f4f7;
  --color-sidebar-search-background: #FFFFFF;
  --color-sidebar-search-border: #FFFFFF;
  --color-sidebar-brand-text: #212529;
  --font-weight: 300;
  --color-link: #049EF4;
  --color-problematic: #FF0080;
  --color-highlight-on-target: #f3f4f7;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../../../contents.html"><div class="brand">auralflow</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon no-toc" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="../../../contents.html">
  
  
  <span class="sidebar-brand-text">auralflow</span>
  
</a><form class="sidebar-search-container" method="get" action="../../../search.html" role="search">
  <input class="sidebar-search" placeholder=Search name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../quickstart.html">Quickstart</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="simple">
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../usage.html">Basic Usage</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../params.html">Parameters</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="simple">
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../api.html">API Documentation</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/auralflow.customs.html">auralflow.customs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/auralflow.datasets.html">auralflow.datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/auralflow.losses.html">auralflow.losses</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/auralflow.models.html">auralflow.models</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/auralflow.trainer.html">auralflow.trainer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/auralflow.transforms.html">auralflow.transforms</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/auralflow.utils.html">auralflow.utils</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../generated/auralflow.visualizer.html">auralflow.visualizer</a></li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          <div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon no-toc" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <h1>Source code for auralflow.models.architectures</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright (c) 2022 Kian Zohoury</span>
<span class="c1"># Distributed under the terms of the MIT License.</span>
<span class="c1"># SPDX-License-Identifier: MIT</span>
<span class="c1"># This code is part of the auralflow project linked below.</span>
<span class="c1"># https://github.com/kianzohoury/auralflow.git</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.backends.cudnn</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>


<span class="kn">from</span> <span class="nn">auralflow.transforms.transforms</span> <span class="kn">import</span> <span class="n">get_deconv_pad</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">FloatTensor</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span>


<span class="c1"># Use CNN GPU optimizations if available.</span>
<span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">True</span>


<span class="k">class</span> <span class="nc">ConvBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Conv =&gt; Batch Norm =&gt; ReLU block.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">bn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">leak</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConvBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
            <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="n">kernel_size</span><span class="p">,</span>
            <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span>
            <span class="n">bias</span><span class="o">=</span><span class="ow">not</span> <span class="n">bn</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Initialize weights depending on activation fn.</span>
        <span class="k">if</span> <span class="n">leak</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LeakyReLU</span><span class="p">(</span><span class="n">leak</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s2">&quot;linear&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SELU</span><span class="p">()</span>

        <span class="c1"># Batch normalization.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span> <span class="k">if</span> <span class="n">bn</span> <span class="k">else</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FloatTensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward method.&quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">class</span> <span class="nc">ConvBlockTriple</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;(Conv =&gt; Batch Norm =&gt; ReLU) x 3 block.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">bn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">leak</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">ConvBlockTriple</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">leak</span><span class="p">),</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">leak</span><span class="p">),</span>
            <span class="n">ConvBlock</span><span class="p">(</span><span class="n">out_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">bn</span><span class="p">,</span> <span class="n">leak</span><span class="p">),</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FloatTensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward method.&quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">class</span> <span class="nc">DownBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Downsampling convolutional block.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">leak</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">reduce</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">bn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">DownBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span> <span class="o">=</span> <span class="n">ConvBlockTriple</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">leak</span><span class="o">=</span><span class="n">leak</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="n">bn</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">reduce</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">down</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">FloatTensor</span><span class="p">,</span> <span class="o">...</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Forward method.&quot;&quot;&quot;</span>
        <span class="n">skip</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down</span><span class="p">(</span><span class="n">skip</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">skip</span>


<span class="k">class</span> <span class="nc">UpBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Upsampling convolutional block.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">padding</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
        <span class="n">kernel_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">drop_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.4</span><span class="p">,</span>
        <span class="n">bn</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">UpBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span> <span class="o">=</span> <span class="n">ConvBlockTriple</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="p">,</span> <span class="n">leak</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="n">bn</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">up</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ConvTranspose2d</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span>
            <span class="n">out_channels</span><span class="o">=</span><span class="n">out_channels</span><span class="p">,</span>
            <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
            <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">padding</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout2d</span><span class="p">(</span><span class="n">drop_p</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">FloatTensor</span><span class="p">,</span> <span class="n">skip</span><span class="p">:</span> <span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FloatTensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward method.&quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">output_size</span><span class="o">=</span><span class="n">skip</span><span class="o">.</span><span class="n">size</span><span class="p">())</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bn</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv_block</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">data</span><span class="p">,</span> <span class="n">skip</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">class</span> <span class="nc">CenterScaleNormalization</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper class for learning centered/scaled representations of data.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_fft_bins</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">use_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">CenterScaleNormalization</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="n">center_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">num_fft_bins</span><span class="p">)</span>
        <span class="n">scale_weights</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">num_fft_bins</span><span class="p">)</span>

        <span class="c1"># Initialize weights.</span>
        <span class="k">if</span> <span class="n">use_norm</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">center_weights</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">uniform_</span><span class="p">(</span><span class="n">scale_weights</span><span class="p">,</span> <span class="n">a</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">b</span><span class="o">=</span><span class="mf">1.1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">zeros_</span><span class="p">(</span><span class="n">center_weights</span><span class="p">)</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">ones_</span><span class="p">(</span><span class="n">scale_weights</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">center</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">center_weights</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">use_norm</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">scale_weights</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="n">use_norm</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FloatTensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward method.&quot;&quot;&quot;</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="n">centered</span> <span class="o">=</span> <span class="n">data</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">center</span>
        <span class="n">scaled</span> <span class="o">=</span> <span class="n">centered</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">scale</span>
        <span class="n">output</span> <span class="o">=</span> <span class="n">scaled</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">class</span> <span class="nc">InputNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper class for learning input centering/scaling.&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_fft_bins</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">apply_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">use_layer_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">num_channels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_frames</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">InputNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">use_layer_norm</span> <span class="ow">and</span> <span class="n">num_channels</span> <span class="ow">and</span> <span class="n">num_frames</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">LayerNorm</span><span class="p">(</span>
                <span class="n">num_fft_bins</span><span class="o">=</span><span class="n">num_fft_bins</span><span class="p">,</span>
                <span class="n">num_channels</span><span class="o">=</span><span class="n">num_channels</span><span class="p">,</span>
                <span class="n">num_frames</span><span class="o">=</span><span class="n">num_frames</span><span class="p">,</span>
                <span class="n">use_norm</span><span class="o">=</span><span class="n">apply_norm</span><span class="p">,</span>
                <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="n">apply_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">CenterScaleNormalization</span><span class="p">(</span>
                <span class="n">num_fft_bins</span><span class="o">=</span><span class="n">num_fft_bins</span><span class="p">,</span> <span class="n">use_norm</span><span class="o">=</span><span class="n">apply_norm</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FloatTensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward method.&quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span><span class="o">.</span><span class="n">forward</span><span class="p">(</span><span class="n">data</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">output</span>


<span class="k">class</span> <span class="nc">LayerNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Wrapper class for layer normalization&quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_fft_bins</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_frames</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">use_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LayerNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">use_norm</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span>
                <span class="n">normalized_shape</span><span class="o">=</span><span class="p">[</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">num_fft_bins</span><span class="p">,</span> <span class="n">num_frames</span><span class="p">],</span>
                <span class="n">device</span><span class="o">=</span><span class="s2">&quot;cpu&quot;</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">device</span> <span class="k">else</span> <span class="n">device</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Identity</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FloatTensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward method.&quot;&quot;&quot;</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">layer_norm</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output</span>


<div class="viewcode-block" id="SpectrogramNetSimple"><a class="viewcode-back" href="../../../auralflow.models.SpectrogramNetSimple.html#auralflow.models.SpectrogramNetSimple">[docs]</a><span class="k">class</span> <span class="nc">SpectrogramNetSimple</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Vanilla spectrogram-based deep mask estimation model.</span>

<span class="sd">    Args:</span>
<span class="sd">        num_fft_bins (int): Number of FFT bins (aka filterbanks).</span>
<span class="sd">        num_frames (int): Number of temporal features (time axis).</span>
<span class="sd">        num_channels (int): 1 for mono, 2 for stereo. Default: 1.</span>
<span class="sd">        hidden_channels (int): Number of initial output channels. Default: 16.</span>
<span class="sd">        mask_act_fn (str): Final activation layer that creates the</span>
<span class="sd">            multiplicative soft-mask. Default: &#39;sigmoid&#39;.</span>
<span class="sd">        leak_factor (float): Alpha constant if using Leaky ReLU activation.</span>
<span class="sd">            Default: 0.</span>
<span class="sd">        dropout_p (float): Dropout probability. Default: 0.5.</span>
<span class="sd">        normalize_input (bool): Whether to learn input normalization</span>
<span class="sd">            parameters. Default: False.</span>
<span class="sd">        normalize_output (bool): Whether to learn output normalization</span>
<span class="sd">            parameters. Default: False.</span>
<span class="sd">        device (optional[str]): Device. Default: None.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_fft_bins</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_frames</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">num_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">hidden_channels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">16</span><span class="p">,</span>
        <span class="n">mask_act_fn</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span>
        <span class="n">leak_factor</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
        <span class="n">dropout_p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">normalize_input</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">normalize_output</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SpectrogramNetSimple</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Register attributes.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_fft_bins</span> <span class="o">=</span> <span class="n">num_fft_bins</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_frames</span> <span class="o">=</span> <span class="n">num_frames</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_channels</span> <span class="o">=</span> <span class="n">num_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_channels</span> <span class="o">=</span> <span class="n">hidden_channels</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation_fn</span> <span class="o">=</span> <span class="n">mask_act_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leak_factor</span> <span class="o">=</span> <span class="n">leak_factor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize_input</span> <span class="o">=</span> <span class="n">normalize_input</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">normalize_output</span> <span class="o">=</span> <span class="n">normalize_output</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device</span>

        <span class="c1"># Define input norm layer. Uses identity fn if not activated.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_norm</span> <span class="o">=</span> <span class="n">InputNorm</span><span class="p">(</span>
            <span class="n">num_fft_bins</span><span class="o">=</span><span class="n">num_fft_bins</span><span class="p">,</span>
            <span class="n">apply_norm</span><span class="o">=</span><span class="n">normalize_input</span><span class="p">,</span>
            <span class="n">use_layer_norm</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">num_channels</span><span class="o">=</span><span class="n">num_channels</span><span class="p">,</span>
            <span class="n">num_frames</span><span class="o">=</span><span class="n">num_frames</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Calculate input/output channel sizes for each layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span> <span class="o">=</span> <span class="p">[[</span><span class="n">num_channels</span><span class="p">,</span> <span class="n">hidden_channels</span><span class="p">]]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">[</span><span class="n">hidden_channels</span> <span class="o">&lt;&lt;</span> <span class="n">i</span><span class="p">,</span> <span class="n">hidden_channels</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span>
            <span class="p">)</span>

        <span class="c1"># Define encoder layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_1</span> <span class="o">=</span> <span class="n">DownBlock</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">leak</span><span class="o">=</span><span class="n">leak_factor</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_2</span> <span class="o">=</span> <span class="n">DownBlock</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">leak</span><span class="o">=</span><span class="n">leak_factor</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_3</span> <span class="o">=</span> <span class="n">DownBlock</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">leak</span><span class="o">=</span><span class="n">leak_factor</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_4</span> <span class="o">=</span> <span class="n">DownBlock</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">leak</span><span class="o">=</span><span class="n">leak_factor</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">down_5</span> <span class="o">=</span> <span class="n">DownBlock</span><span class="p">(</span>
            <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">leak</span><span class="o">=</span><span class="n">leak_factor</span><span class="p">,</span> <span class="n">bn</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="c1"># self.down_6 = DownBlock(</span>
        <span class="c1">#     *self.channel_sizes[5], leak=leak_factor, bn=True</span>
        <span class="c1"># )</span>

        <span class="c1"># Define simple bottleneck layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck</span> <span class="o">=</span> <span class="n">ConvBlockTriple</span><span class="p">(</span>
            <span class="n">in_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">out_channels</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">leak</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Determine the spatial dimension sizes for computing deconv padding.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">encoding_sizes</span> <span class="o">=</span> <span class="p">[</span>
            <span class="p">[</span><span class="n">num_fft_bins</span> <span class="o">&gt;&gt;</span> <span class="n">i</span><span class="p">,</span> <span class="n">num_frames</span> <span class="o">&gt;&gt;</span> <span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">)</span>
        <span class="p">]</span>

        <span class="c1"># Compute transpose/deconvolution padding.</span>
        <span class="n">padding_sizes</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">encoding_sizes</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):</span>
            <span class="n">padding_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="n">get_deconv_pad</span><span class="p">(</span>
                    <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">encoding_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span> <span class="o">-</span> <span class="n">i</span><span class="p">],</span>
                    <span class="o">*</span><span class="bp">self</span><span class="o">.</span><span class="n">encoding_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span> <span class="o">-</span> <span class="n">i</span><span class="p">],</span>
                    <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                    <span class="n">kernel_size</span><span class="o">=</span><span class="mi">5</span>
                <span class="p">)</span>
            <span class="p">)</span>

        <span class="c1"># Deconvolution channel sizes.</span>
        <span class="n">dec_channel_sizes</span> <span class="o">=</span> <span class="p">[</span><span class="n">size</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">size</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span><span class="p">][::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

        <span class="c1"># Define decoder layers. Use dropout for first 3 decoder layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">up_1</span> <span class="o">=</span> <span class="n">UpBlock</span><span class="p">(</span>
            <span class="o">*</span><span class="n">dec_channel_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">padding_sizes</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span>
            <span class="n">drop_p</span><span class="o">=</span><span class="n">dropout_p</span><span class="p">,</span>
            <span class="n">bn</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">up_2</span> <span class="o">=</span> <span class="n">UpBlock</span><span class="p">(</span>
            <span class="o">*</span><span class="n">dec_channel_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">padding_sizes</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>
            <span class="n">drop_p</span><span class="o">=</span><span class="n">dropout_p</span><span class="p">,</span>
            <span class="n">bn</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">up_3</span> <span class="o">=</span> <span class="n">UpBlock</span><span class="p">(</span>
            <span class="o">*</span><span class="n">dec_channel_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
            <span class="n">padding</span><span class="o">=</span><span class="n">padding_sizes</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span>
            <span class="n">drop_p</span><span class="o">=</span><span class="n">dropout_p</span><span class="p">,</span>
            <span class="n">bn</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">up_4</span> <span class="o">=</span> <span class="n">UpBlock</span><span class="p">(</span>
            <span class="o">*</span><span class="n">dec_channel_sizes</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding_sizes</span><span class="p">[</span><span class="mi">3</span><span class="p">],</span> <span class="n">bn</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">up_5</span> <span class="o">=</span> <span class="n">UpBlock</span><span class="p">(</span>
            <span class="o">*</span><span class="n">dec_channel_sizes</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="n">padding_sizes</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="n">bn</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>
        <span class="c1"># self.up_6 = UpBlock(</span>
        <span class="c1">#     *dec_channel_sizes[5], padding=padding_sizes[5], bn=True</span>
        <span class="c1"># )</span>

        <span class="c1"># Final conv layer squeezes output channels dimension to num_channels.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">soft_conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
                <span class="n">in_channels</span><span class="o">=</span><span class="n">hidden_channels</span><span class="p">,</span>
                <span class="n">out_channels</span><span class="o">=</span><span class="n">num_channels</span><span class="p">,</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_channels</span><span class="p">)</span>
        <span class="p">)</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">phase_head</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
                <span class="n">in_channels</span><span class="o">=</span><span class="n">hidden_channels</span><span class="p">,</span>
                <span class="n">out_channels</span><span class="o">=</span><span class="n">num_channels</span><span class="p">,</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">stride</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="s2">&quot;same&quot;</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">num_channels</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="p">)</span>

        <span class="c1"># Define output norm layer. Uses identity fn if not activated.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">output_norm</span> <span class="o">=</span> <span class="n">CenterScaleNormalization</span><span class="p">(</span>
            <span class="n">num_fft_bins</span><span class="o">=</span><span class="n">num_fft_bins</span><span class="p">,</span> <span class="n">use_norm</span><span class="o">=</span><span class="n">normalize_output</span>
        <span class="p">)</span>

        <span class="c1"># Define activation function used for final masking step.</span>
        <span class="k">if</span> <span class="n">mask_act_fn</span> <span class="o">==</span> <span class="s2">&quot;relu&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mask_act_fn</span> <span class="o">==</span> <span class="s2">&quot;hardtanh&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Hardtanh</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mask_act_fn</span> <span class="o">==</span> <span class="s2">&quot;tanh&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">mask_act_fn</span> <span class="o">==</span> <span class="s2">&quot;softmax&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Softmax</span><span class="p">()</span>
        <span class="k">elif</span> <span class="n">mask_act_fn</span> <span class="o">==</span> <span class="s2">&quot;prelu&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">PReLU</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mask_act_fn</span> <span class="o">==</span> <span class="s2">&quot;selu&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">SELU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">mask_act_fn</span> <span class="o">==</span> <span class="s2">&quot;elu&quot;</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ELU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

<div class="viewcode-block" id="SpectrogramNetSimple.forward"><a class="viewcode-back" href="../../../auralflow.models.SpectrogramNetSimple.html#auralflow.models.SpectrogramNetSimple.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FloatTensor</span><span class="p">:</span>
        <span class="sa">r</span><span class="sd">&quot;&quot;&quot;Forward method that estimates the source mask.</span>

<span class="sd">        Args:</span>
<span class="sd">            data (FloatTensor): Input spectrogram.</span>

<span class="sd">        Shape:</span>
<span class="sd">            - input: :math:`(N, C, F, T)`</span>
<span class="sd">            - output: :math:`(N, C, F, T)`</span>

<span class="sd">            where</span>
<span class="sd">                - :math:`N`: batch size</span>
<span class="sd">                - :math:`C`: number of channels</span>
<span class="sd">                - :math:`F`: number of frequency bins</span>
<span class="sd">                - :math:`T`: number of frames</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Normalize input if applicable.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_norm</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Pass through encoder.</span>
        <span class="n">enc_1</span><span class="p">,</span> <span class="n">skip_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_1</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">enc_2</span><span class="p">,</span> <span class="n">skip_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_2</span><span class="p">(</span><span class="n">enc_1</span><span class="p">)</span>
        <span class="n">enc_3</span><span class="p">,</span> <span class="n">skip_3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_3</span><span class="p">(</span><span class="n">enc_2</span><span class="p">)</span>
        <span class="n">enc_4</span><span class="p">,</span> <span class="n">skip_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_4</span><span class="p">(</span><span class="n">enc_3</span><span class="p">)</span>
        <span class="n">enc_5</span><span class="p">,</span> <span class="n">skip_5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_5</span><span class="p">(</span><span class="n">enc_4</span><span class="p">)</span>
        <span class="c1"># enc_6, skip_6 = self.down_6(enc_5)</span>

        <span class="c1"># Pass through bottleneck.</span>
        <span class="n">latent_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">bottleneck</span><span class="p">(</span><span class="n">enc_5</span><span class="p">)</span>

        <span class="c1"># Pass through decoder.</span>
        <span class="n">dec_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_1</span><span class="p">(</span><span class="n">latent_data</span><span class="p">,</span> <span class="n">skip_5</span><span class="p">)</span>
        <span class="n">dec_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_2</span><span class="p">(</span><span class="n">dec_1</span><span class="p">,</span> <span class="n">skip_4</span><span class="p">)</span>
        <span class="n">dec_3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_3</span><span class="p">(</span><span class="n">dec_2</span><span class="p">,</span> <span class="n">skip_3</span><span class="p">)</span>
        <span class="n">dec_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_4</span><span class="p">(</span><span class="n">dec_3</span><span class="p">,</span> <span class="n">skip_2</span><span class="p">)</span>
        <span class="n">dec_5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_5</span><span class="p">(</span><span class="n">dec_4</span><span class="p">,</span> <span class="n">skip_1</span><span class="p">)</span>
        <span class="c1"># dec_6 = self.up_6(dec_5, skip_1)</span>

        <span class="c1"># Pass through final 1x1 conv and normalize output if applicable.</span>
        <span class="n">dec_final</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">soft_conv</span><span class="p">(</span><span class="n">dec_5</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_norm</span><span class="p">(</span><span class="n">dec_final</span><span class="p">)</span>

        <span class="c1"># Generate multiplicative soft-mask.</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">mask</span></div></div>


<div class="viewcode-block" id="SpectrogramNetLSTM"><a class="viewcode-back" href="../../../auralflow.models.SpectrogramNetLSTM.html#auralflow.models.SpectrogramNetLSTM">[docs]</a><span class="k">class</span> <span class="nc">SpectrogramNetLSTM</span><span class="p">(</span><span class="n">SpectrogramNetSimple</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Deep mask estimation model using LSTM bottleneck layers.</span>

<span class="sd">    Args:</span>
<span class="sd">        recurrent_depth (int): Number of stacked lstm layers. Default: 3.</span>
<span class="sd">        hidden_size (int): Requested number of hidden features. Default: 1024.</span>
<span class="sd">        input_axis (int): Whether to feed dim 0 (frequency axis) or dim 1</span>
<span class="sd">            (time axis) as features to the lstm. Default: 1.</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        args: Positional arguments for constructor.</span>
<span class="sd">        kwargs: Additional keyword arguments for constructor.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="o">*</span><span class="n">args</span><span class="p">,</span>
        <span class="n">recurrent_depth</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">3</span><span class="p">,</span>
        <span class="n">hidden_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>
        <span class="n">input_axis</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SpectrogramNetLSTM</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">recurrent_depth</span> <span class="o">=</span> <span class="n">recurrent_depth</span>

        <span class="c1"># Set to min between last channel size to avoid over-parameterization.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">hidden_size</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">input_axis</span> <span class="o">=</span> <span class="n">input_axis</span>

        <span class="c1"># Calculate num in features for LSTM and store ordering of tensor dims.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">channel_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">input_axis</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoding_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_perm</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_perm</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoding_sizes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">input_perm</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">output_perm</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>

        <span class="c1"># Define recurrent stack.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">(</span>
            <span class="n">input_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span>
            <span class="n">hidden_size</span><span class="o">=</span><span class="n">hidden_size</span><span class="p">,</span>
            <span class="n">bidirectional</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="n">num_layers</span><span class="o">=</span><span class="n">recurrent_depth</span><span class="p">,</span>
            <span class="n">dropout</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="c1"># Define dense layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">hidden_size</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">SELU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span> <span class="o">*</span> <span class="mi">2</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">SELU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span>
        <span class="p">)</span>

<div class="viewcode-block" id="SpectrogramNetLSTM.forward"><a class="viewcode-back" href="../../../auralflow.models.SpectrogramNetLSTM.html#auralflow.models.SpectrogramNetLSTM.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FloatTensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward method.&quot;&quot;&quot;</span>
        <span class="c1"># Normalize input if applicable.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_norm</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Pass through encoder.</span>
        <span class="n">enc_1</span><span class="p">,</span> <span class="n">skip_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_1</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">enc_2</span><span class="p">,</span> <span class="n">skip_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_2</span><span class="p">(</span><span class="n">enc_1</span><span class="p">)</span>
        <span class="n">enc_3</span><span class="p">,</span> <span class="n">skip_3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_3</span><span class="p">(</span><span class="n">enc_2</span><span class="p">)</span>
        <span class="n">enc_4</span><span class="p">,</span> <span class="n">skip_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_4</span><span class="p">(</span><span class="n">enc_3</span><span class="p">)</span>
        <span class="n">enc_5</span><span class="p">,</span> <span class="n">skip_5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_5</span><span class="p">(</span><span class="n">enc_4</span><span class="p">)</span>
        <span class="c1"># enc_6, skip_6 = self.down_6(enc_5)</span>

        <span class="c1"># Reshape encoded audio to pass through bottleneck.</span>
        <span class="n">enc_5</span> <span class="o">=</span> <span class="n">enc_5</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_perm</span><span class="p">)</span>
        <span class="n">n_batch</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">n_channel</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="n">enc_5</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">enc_5</span> <span class="o">=</span> <span class="n">enc_5</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_batch</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">n_channel</span> <span class="o">*</span> <span class="n">dim2</span><span class="p">))</span>

        <span class="c1"># Pass through recurrent stack.</span>
        <span class="n">lstm_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="n">enc_5</span><span class="p">)</span>
        <span class="n">lstm_out</span> <span class="o">=</span> <span class="n">lstm_out</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_batch</span> <span class="o">*</span> <span class="n">dim1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Project latent audio onto affine space, and reshape for decoder.</span>
        <span class="n">latent_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">)</span>
        <span class="n">latent_data</span> <span class="o">=</span> <span class="n">latent_data</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_batch</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">n_channel</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="p">))</span>
        <span class="n">latent_data</span> <span class="o">=</span> <span class="n">latent_data</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_perm</span><span class="p">)</span>

        <span class="c1"># Pass through decoder.</span>
        <span class="n">dec_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_1</span><span class="p">(</span><span class="n">latent_data</span><span class="p">,</span> <span class="n">skip_5</span><span class="p">)</span>
        <span class="n">dec_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_2</span><span class="p">(</span><span class="n">dec_1</span><span class="p">,</span> <span class="n">skip_4</span><span class="p">)</span>
        <span class="n">dec_3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_3</span><span class="p">(</span><span class="n">dec_2</span><span class="p">,</span> <span class="n">skip_3</span><span class="p">)</span>
        <span class="n">dec_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_4</span><span class="p">(</span><span class="n">dec_3</span><span class="p">,</span> <span class="n">skip_2</span><span class="p">)</span>
        <span class="n">dec_5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_5</span><span class="p">(</span><span class="n">dec_4</span><span class="p">,</span> <span class="n">skip_1</span><span class="p">)</span>
        <span class="c1"># dec_6 = self.up_6(dec_5, skip_1)</span>

        <span class="c1"># Pass through final 1x1 conv and normalize output if applicable.</span>
        <span class="n">dec_final</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">soft_conv</span><span class="p">(</span><span class="n">dec_5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">phase_mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">phase_head</span><span class="p">(</span><span class="n">dec_5</span><span class="p">),</span> <span class="nb">min</span><span class="o">=-</span><span class="mf">3.14</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">3.14</span>
        <span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>

        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_norm</span><span class="p">(</span><span class="n">dec_final</span><span class="p">)</span>

        <span class="c1"># Generate multiplicative soft-mask.</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="nb">min</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">mask</span></div>

<div class="viewcode-block" id="SpectrogramNetLSTM.split_lstm_parameters"><a class="viewcode-back" href="../../../auralflow.models.SpectrogramNetLSTM.html#auralflow.models.SpectrogramNetLSTM.split_lstm_parameters">[docs]</a>    <span class="k">def</span> <span class="nf">split_lstm_parameters</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">,</span> <span class="nb">list</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Separates model&#39;s LSTM parameters from non-LSTM parameters.&quot;&quot;&quot;</span>
        <span class="n">lstm_params</span><span class="p">,</span> <span class="n">other_params</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">param_name</span><span class="p">,</span> <span class="n">param_val</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">param_name</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot;.&quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;lstm&quot;</span><span class="p">,</span> <span class="s2">&quot;linear&quot;</span><span class="p">]:</span>
                <span class="n">lstm_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param_val</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">other_params</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">param_val</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">lstm_params</span><span class="p">,</span> <span class="n">other_params</span></div></div>


<div class="viewcode-block" id="SpectrogramNetVAE"><a class="viewcode-back" href="../../../auralflow.models.SpectrogramNetVAE.html#auralflow.models.SpectrogramNetVAE">[docs]</a><span class="k">class</span> <span class="nc">SpectrogramNetVAE</span><span class="p">(</span><span class="n">SpectrogramNetLSTM</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Spectrogram U-Net model with a VAE and LSTM bottleneck.</span>

<span class="sd">    Encoder =&gt; VAE =&gt; LSTM x 3 =&gt; decoder. Models a Gaussian conditional</span>
<span class="sd">    distribution p(z|x) to sample latent variable z ~ p(z|x), to feed into</span>
<span class="sd">    decoder to generate x&#39; ~ p(x|z).</span>

<span class="sd">    Keyword Args:</span>
<span class="sd">        args: Positional arguments for constructor.</span>
<span class="sd">        kwargs: Additional keyword arguments for constructor.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">latent_data</span><span class="p">:</span> <span class="n">FloatTensor</span>
    <span class="n">mu_data</span><span class="p">:</span> <span class="n">FloatTensor</span>
    <span class="n">sigma_data</span><span class="p">:</span> <span class="n">FloatTensor</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">SpectrogramNetVAE</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

        <span class="c1"># Define normalizing flow layers.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_sigma</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_features</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">eps</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">Normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

        <span class="c1"># Speed up sampling by utilizing GPU.</span>
        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">():</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="o">.</span><span class="n">loc</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="o">.</span><span class="n">loc</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="o">.</span><span class="n">scale</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="o">.</span><span class="n">scale</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>

<div class="viewcode-block" id="SpectrogramNetVAE.forward"><a class="viewcode-back" href="../../../auralflow.models.SpectrogramNetVAE.html#auralflow.models.SpectrogramNetVAE.forward">[docs]</a>    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">:</span> <span class="n">FloatTensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">FloatTensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Forward method.&quot;&quot;&quot;</span>
        <span class="c1"># Normalize input if applicable.</span>
        <span class="n">data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">input_norm</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

        <span class="c1"># Pass through encoder.</span>
        <span class="n">enc_1</span><span class="p">,</span> <span class="n">skip_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_1</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
        <span class="n">enc_2</span><span class="p">,</span> <span class="n">skip_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_2</span><span class="p">(</span><span class="n">enc_1</span><span class="p">)</span>
        <span class="n">enc_3</span><span class="p">,</span> <span class="n">skip_3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_3</span><span class="p">(</span><span class="n">enc_2</span><span class="p">)</span>
        <span class="n">enc_4</span><span class="p">,</span> <span class="n">skip_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_4</span><span class="p">(</span><span class="n">enc_3</span><span class="p">)</span>
        <span class="n">enc_5</span><span class="p">,</span> <span class="n">skip_5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_5</span><span class="p">(</span><span class="n">enc_4</span><span class="p">)</span>
        <span class="n">enc_6</span><span class="p">,</span> <span class="n">skip_6</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">down_6</span><span class="p">(</span><span class="n">enc_5</span><span class="p">)</span>

        <span class="c1"># Reshape encodings to match dimensions of latent space.</span>
        <span class="n">enc_6</span> <span class="o">=</span> <span class="n">enc_6</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">input_perm</span><span class="p">)</span>
        <span class="n">n_batch</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">n_channel</span><span class="p">,</span> <span class="n">dim2</span> <span class="o">=</span> <span class="n">enc_6</span><span class="o">.</span><span class="n">size</span><span class="p">()</span>
        <span class="n">enc_6</span> <span class="o">=</span> <span class="n">enc_6</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_batch</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">n_channel</span> <span class="o">*</span> <span class="n">dim2</span><span class="p">))</span>

        <span class="c1"># Normalizing flow.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">mu_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu</span><span class="p">(</span><span class="n">enc_6</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sigma_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">log_sigma</span><span class="p">(</span><span class="n">enc_6</span><span class="p">))</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
        <span class="n">eps</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">eps</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">sample_shape</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">sigma_data</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

        <span class="c1"># Sample z from the modeled distribution.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">latent_data</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mu_data</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">sigma_data</span> <span class="o">*</span> <span class="n">eps</span>

        <span class="c1"># Pass through recurrent stack.</span>
        <span class="n">lstm_out</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">lstm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">latent_data</span><span class="p">)</span>
        <span class="n">lstm_out</span> <span class="o">=</span> <span class="n">lstm_out</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_batch</span> <span class="o">*</span> <span class="n">dim1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="c1"># Pass through affine layers and reshape for decoder.</span>
        <span class="n">dec_0</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">lstm_out</span><span class="p">)</span>
        <span class="n">dec_0</span> <span class="o">=</span> <span class="n">dec_0</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="n">n_batch</span><span class="p">,</span> <span class="n">dim1</span><span class="p">,</span> <span class="n">n_channel</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim2</span><span class="p">))</span>
        <span class="n">dec_0</span> <span class="o">=</span> <span class="n">dec_0</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">output_perm</span><span class="p">)</span>

        <span class="c1"># Pass through decoder.</span>
        <span class="n">dec_1</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_1</span><span class="p">(</span><span class="n">dec_0</span><span class="p">,</span> <span class="n">skip_6</span><span class="p">)</span>
        <span class="n">dec_2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_2</span><span class="p">(</span><span class="n">dec_1</span><span class="p">,</span> <span class="n">skip_5</span><span class="p">)</span>
        <span class="n">dec_3</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_3</span><span class="p">(</span><span class="n">dec_2</span><span class="p">,</span> <span class="n">skip_4</span><span class="p">)</span>
        <span class="n">dec_4</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_4</span><span class="p">(</span><span class="n">dec_3</span><span class="p">,</span> <span class="n">skip_3</span><span class="p">)</span>
        <span class="n">dec_5</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_5</span><span class="p">(</span><span class="n">dec_4</span><span class="p">,</span> <span class="n">skip_2</span><span class="p">)</span>
        <span class="n">dec_6</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">up_6</span><span class="p">(</span><span class="n">dec_5</span><span class="p">,</span> <span class="n">skip_1</span><span class="p">)</span>

        <span class="c1"># Pass through final 1x1 conv and normalize output if applicable.</span>
        <span class="n">dec_final</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">soft_conv</span><span class="p">(</span><span class="n">dec_6</span><span class="p">)</span>
        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">output_norm</span><span class="p">(</span><span class="n">dec_final</span><span class="p">)</span>

        <span class="c1"># Generate multiplicative soft-mask.</span>
        <span class="n">mask</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">mask_activation</span><span class="p">(</span><span class="n">output</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">mask</span></div></div>
</pre></div>
        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2022, Kian Zohoury
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer no-toc">
      
      
      
    </aside>
  </div>
</div><script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/scripts/furo.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    </body>
</html>